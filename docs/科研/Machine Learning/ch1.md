# 符号与定义

## 常用术语列表

- **方差 (Variance)**：衡量数据分布的离散程度，表示数据与其均值的偏离程度。计算公式为样本数据每个值与均值的平方差的平均值。
- **偏差 (Bias)**：模型预测值的期望与真实值之间的差异，衡量模型的系统性误差。
- **残差 (Residual)**：实际观测值与模型预测值之间的差异。残差反映了模型对特定数据点的预测误差。
- **参数 (Parameter)**：在模型中定义数据之间关系的系数，如线性回归中的斜率和截距。
- **熵 (Entropy)**：衡量系统的混乱度或不确定性。熵越高，系统的混乱度越大。信息熵常用于分类模型中来评估模型的不确定性。
- **局部最小值 (Local Minimum)**：在某一有限范围内，函数值小于其邻域内所有其他点的值，但不一定是全局最小值。
- **全局最小值 (Global Minimum)**：在整个定义域内，函数值小于或等于其他所有点的值，代表了函数的最低点。
- **收敛 (Convergence)**：在迭代优化过程中，算法逐步逼近一个稳定的解（通常是极小值或极大值）。
- **质心 (Centroid)**：聚类算法中，质心是簇内所有点的中心点，表示该簇的平均位置。
- **周期 (Epoch)**：在机器学习中，一个周期指的是模型对整个训练数据集进行一次完整的学习过程。
- **超平面 (Hyperplane)**：在 $n$ 维空间中，将空间划分为两个部分的 $n-1$ 维平面。在线性分类问题中，超平面用于分割不同类别的数据点。
- **神经元 (Neuron/Neural)**：神经网络的基本计算单元，通过激活函数处理输入特征来产生输出。

## 数学符号

### 线性代数

- **向量引用**：例如，$\vec{a} = [-1,-2,-3]$ 中 $\vec{a}^{(2)}$ 并不是向量的平方，而是指向量中的第 2 个元素，也就是 -2。这种记号本质上是一种引用记号，表示对向量中特定维度的引用。
  
- **多重下标**：例如 $x_{l,u}^{(j)}$，在神经网络中表示第 $l$ 层神经元中的第 $u$ 个单元的第 $j$ 维输入特征。下标的使用可以在多个维度上进行参数区分和标识。

### 微积分

- **求最大值的元素**： $\underset{a \in A}{\text{argmax}} f(a)$ 表示使 $f(a)$ 最大的元素 $a$。在优化问题中，argmax 操作用于找到使目标函数达到最大值的输入。
  
- **梯度**：梯度通常用下三角符号 $\triangledown$ 表示，表示函数相对于其输入变量的偏导数向量。梯度的方向是函数值增长最快的方向。

### 概率与数理统计

- **随机变量**：随机变量有两种类型：离散型和连续型。对于离散型随机变量，使用求和符号计算其期望和概率。对于连续型随机变量，使用定积分计算其期望和概率密度函数。

- **无偏估计 (Unbiased Estimator)**：假如我们从一个未知的统计分布中抽取样本 $S_x$ ，并计算得到一些统计特征 $\theta$。只有当 $E[\hat{\theta}(S_X)] = \theta$ 成立时，我们称 $\hat{\theta}(S_x)$ 是一个无偏估计值。其中 $\hat{\theta}$ 是样本统计特征，若有无数个样本，则这些样本的均值的期望等于总体均值。

- **贝叶斯定理 (Bayes Theorem)**：
  $P(A|B) = \frac{P(B|A)P(A)}{P(B)}$
  其中 $P(A)$ 是先验概率（prior），$P(B|A)$ 是似然（likelihood），$P(A|B)$ 是后验概率（posterior）。

- **参数估计 (Parameter Estimation)**：贝叶斯准则适用于一个表示 $X$ 的分布，并且含有一个向量 $\theta$ 作为参数的模型 $f_{\theta}$。给定一个样本，我们可以用极大似然法得到最优的参数 $\theta^*$：
  $\theta^* = \underset{\theta}{\text{argmax}} \prod_{i=1}^N P(\theta=\hat{\theta}|X=x_i)$
  如果 $\theta$ 有无限个可能值，则需要利用数值优化方法，如梯度下降等。